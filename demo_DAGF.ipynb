{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Atrous Guided Filter Demo\n",
    "This notebook provides simple demo code to view the restoration performed by our *Deep Atrous Guided Filter* (DAGF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under-Display Camera Challenge\n",
    "\n",
    "Under-Display Camera (UDC) is a new imaging system where the camera is placed behind the display screen, achieving truly bezel-free displays, larger screen-to-body ratio, superior video conferencing experience, etc. The [Under-Display Camera Challenge](https://rlq-tod.github.io/challenge2.html), held in conjunction with the RLQ'20 Workshop in ECCV 2020, sought efficient and high performing solutions for restoration of high-resolution Transparent-OLED (TOLED) and Pentile OLED (POLED) UDC images. UDC images suffer from a variety of degradations, including blur, low-light and colour degradation. Our method, *DAGF*, operates directly on the high-resolution images, maintaining efficiency by using a guided-filter framework. DAGF is effective in restoring highly  degraded POLED images, by incorporating larger context (through atrous convolutions) and imitating multi-scale processing (by employing such convolutions in parallel). Our method placed 2nd in the POLED track and 5th in the TOLED track.\n",
    "\n",
    "![](figs/fig_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DAGF Overview\n",
    "Our model restores an image in two-stages : A low-resolution network (LRNet) first restores the image at a lower resolution, which is subsequently used by the Guided Filter Network as a filtering input to produce a high-resolution output.\n",
    "![](figs/fig_2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/S-aiueo32/contextual_loss_pytorch.git (from -r requirements.txt (line 14))\r\n",
      "  Cloning https://github.com/S-aiueo32/contextual_loss_pytorch.git to /private/var/folders/91/ym4gmlrd0tq37lhq_5x9b_n80000gn/T/pip-req-build-_ohnckhz\r\n",
      "  Running command git clone -q https://github.com/S-aiueo32/contextual_loss_pytorch.git /private/var/folders/91/ym4gmlrd0tq37lhq_5x9b_n80000gn/T/pip-req-build-_ohnckhz\r\n",
      "Requirement already satisfied (use --upgrade to upgrade): contextual-loss-pytorch===latest from git+https://github.com/S-aiueo32/contextual_loss_pytorch.git in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from -r requirements.txt (line 14))\r\n",
      "Requirement already satisfied: sacred in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (0.8.1)\r\n",
      "Requirement already satisfied: numpy in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.19.1)\r\n",
      "Requirement already satisfied: opencv-contrib-python in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (4.3.0.36)\r\n",
      "Requirement already satisfied: matplotlib in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (3.3.0)\r\n",
      "Requirement already satisfied: tqdm in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (4.48.2)\r\n",
      "Requirement already satisfied: h5py in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (2.10.0)\r\n",
      "Requirement already satisfied: future in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (0.18.2)\r\n",
      "Requirement already satisfied: scipy in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (1.5.2)\r\n",
      "Requirement already satisfied: recordclass in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (0.13.2)\r\n",
      "Requirement already satisfied: scikit-image in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (0.17.2)\r\n",
      "Requirement already satisfied: torchsummary in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from -r requirements.txt (line 11)) (1.5.1)\r\n",
      "Requirement already satisfied: common in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from -r requirements.txt (line 12)) (0.1.2)\r\n",
      "Requirement already satisfied: pytorch-msssim in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from -r requirements.txt (line 13)) (0.2.0)\r\n",
      "Requirement already satisfied: torch in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from contextual-loss-pytorch===latest->-r requirements.txt (line 14)) (1.6.0)\r\n",
      "Requirement already satisfied: torchvision in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from contextual-loss-pytorch===latest->-r requirements.txt (line 14)) (0.7.0)\r\n",
      "Requirement already satisfied: wrapt<2.0,>=1.0 in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from sacred->-r requirements.txt (line 1)) (1.12.1)\r\n",
      "Requirement already satisfied: colorama>=0.4 in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from sacred->-r requirements.txt (line 1)) (0.4.3)\r\n",
      "Requirement already satisfied: munch<3.0,>=2.0.2 in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from sacred->-r requirements.txt (line 1)) (2.5.0)\r\n",
      "Requirement already satisfied: py-cpuinfo>=4.0 in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from sacred->-r requirements.txt (line 1)) (7.0.0)\r\n",
      "Requirement already satisfied: GitPython in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from sacred->-r requirements.txt (line 1)) (3.1.7)\r\n",
      "Requirement already satisfied: packaging>=18.0 in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from sacred->-r requirements.txt (line 1)) (20.4)\r\n",
      "Requirement already satisfied: docopt<1.0,>=0.3 in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from sacred->-r requirements.txt (line 1)) (0.6.2)\r\n",
      "Requirement already satisfied: jsonpickle<2.0,>=1.2 in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from sacred->-r requirements.txt (line 1)) (1.4.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 4)) (0.10.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 4)) (2.8.1)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 4)) (2.4.7)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 4)) (7.2.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 4)) (1.2.0)\r\n",
      "Requirement already satisfied: six in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from h5py->-r requirements.txt (line 6)) (1.15.0)\r\n",
      "Requirement already satisfied: networkx>=2.0 in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from scikit-image->-r requirements.txt (line 10)) (2.4)\r\n",
      "Requirement already satisfied: imageio>=2.3.0 in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from scikit-image->-r requirements.txt (line 10)) (2.9.0)\r\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from scikit-image->-r requirements.txt (line 10)) (2020.7.24)\r\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from scikit-image->-r requirements.txt (line 10)) (1.1.1)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from GitPython->sacred->-r requirements.txt (line 1)) (4.0.5)\r\n",
      "Requirement already satisfied: importlib-metadata in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from jsonpickle<2.0,>=1.2->sacred->-r requirements.txt (line 1)) (1.7.0)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from networkx>=2.0->scikit-image->-r requirements.txt (line 10)) (4.4.2)\r\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython->sacred->-r requirements.txt (line 1)) (3.0.4)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/Ankivarun/anaconda3/envs/torch38/lib/python3.8/site-packages (from importlib-metadata->jsonpickle<2.0,>=1.2->sacred->-r requirements.txt (line 1)) (3.1.0)\r\n",
      "Building wheels for collected packages: contextual-loss-pytorch\r\n",
      "  Building wheel for contextual-loss-pytorch (setup.py) ... \u001B[?25l-\b \b\\\b \bdone\r\n",
      "\u001B[?25h  Created wheel for contextual-loss-pytorch: filename=contextual_loss_pytorch-latest-py3-none-any.whl size=7323 sha256=1a9a526e13bc91d48d24b2594c7708f4356fe6f6c1751021fc685466830a6db6\r\n",
      "  Stored in directory: /private/var/folders/91/ym4gmlrd0tq37lhq_5x9b_n80000gn/T/pip-ephem-wheel-cache-_jmp_dz0/wheels/78/98/8b/ee9c552ea8ad17fe35e5d9c48a41829af42a8d8411a0703e0a\r\n",
      "Successfully built contextual-loss-pytorch\r\n"
     ]
    }
   ],
   "source": [
    "# install requirements\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"image_dir\": Path(\"data\"),\n",
    "    \"ckpt_dir\": Path(\"ckpts\"),\n",
    "    \"pixelshuffle_ratio\": 2,\n",
    "    \"guided_map_kernel_size\": 3,\n",
    "    \"guided_map_channels\": 16,\n",
    "    \"device\": \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "\n",
    "\n",
    "# Convert dictionary to object notation\n",
    "class Tupperware(object):\n",
    "    def __init__(self, entries):\n",
    "        self.__dict__.update(entries)\n",
    "        \n",
    "args = Tupperware(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-08-10 10:52:56--  https://docs.google.com/uc?export=download&id=1F_5ddx4ooIwFKFc4ewpb_CPUVCcUN25r\r\n",
      "Resolving docs.google.com (docs.google.com)... 142.250.67.46\r\n",
      "Connecting to docs.google.com (docs.google.com)|142.250.67.46|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\r\n",
      "Location: https://doc-08-58-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/mg4mcr28qrt7nrh2cespto26pvcl5klb/1597036950000/05935635026363679465/*/1F_5ddx4ooIwFKFc4ewpb_CPUVCcUN25r?e=download [following]\r\n",
      "Warning: wildcards not supported in HTTP.\r\n",
      "--2020-08-10 10:52:57--  https://doc-08-58-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/mg4mcr28qrt7nrh2cespto26pvcl5klb/1597036950000/05935635026363679465/*/1F_5ddx4ooIwFKFc4ewpb_CPUVCcUN25r?e=download\r\n",
      "Resolving doc-08-58-docs.googleusercontent.com (doc-08-58-docs.googleusercontent.com)... 216.58.197.65\r\n",
      "Connecting to doc-08-58-docs.googleusercontent.com (doc-08-58-docs.googleusercontent.com)|216.58.197.65|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: unspecified [application/octet-stream]\r\n",
      "Saving to: ‘ckpts/poled_final.pth’\r\n",
      "\r\n",
      "ckpts/poled_final.p     [  <=>               ]   5.85M   301KB/s               "
     ]
    }
   ],
   "source": [
    "# download pre-trained weights for POLED and TOLED\n",
    "if not args.ckpt_dir.exists():\n",
    "    os.mkdir(args.ckpt_dir)\n",
    "    \n",
    "poled_path = str(args.ckpt_dir / 'poled_final.pth')\n",
    "toled_path = str(args.ckpt_dir / 'toled_final.pth')\n",
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1F_5ddx4ooIwFKFc4ewpb_CPUVCcUN25r' -O {poled_path}\n",
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Fmub65AsMK231czImqsZWprxDCNx21AA' -O {toled_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from models.guided_filter import DeepAtrousGuidedFilter\n",
    "from utils.model_serialization import load_state_dict\n",
    "device = args.device\n",
    "model = DeepAtrousGuidedFilter(args).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Poled demo\n",
    "poled_img_path = args.image_dir / \"ex_poled.png\"\n",
    "poled_img = cv2.imread(str(poled_img_path))[:,:,::-1]/255\n",
    "\n",
    "# visualise image\n",
    "plt.figure(figsize=(10, 20))\n",
    "plt.imshow(poled_img)\n",
    "plt.title('POLED image')\n",
    "# preprocessing\n",
    "poled_img = torch.Tensor(poled_img.copy()).permute(2, 0, 1).unsqueeze(0)\n",
    "poled_img = poled_img.mul(2).sub(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# load pre-trained weights\n",
    "ckpt = torch.load(poled_path, map_location=torch.device(device))\n",
    "load_state_dict(model, ckpt['state_dict'])\n",
    "\n",
    "with torch.no_grad():\n",
    "    poled_out = model(poled_img.to(device))[0].cpu().permute(1,2,0).numpy()\n",
    "poled_out = (poled_out + 1)/2\n",
    "plt.figure(figsize=(10, 20))\n",
    "plt.imshow(poled_out)\n",
    "plt.title('Restored POLED image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Toled demo\n",
    "toled_img_path = args.image_dir / \"ex_toled.png\"\n",
    "toled_img = cv2.imread(str(toled_img_path))[:,:,::-1]/255\n",
    "\n",
    "# visualise image\n",
    "plt.figure(figsize=(10, 20))\n",
    "plt.imshow(toled_img)\n",
    "plt.title('TOLED image')\n",
    "\n",
    "# preprocessing\n",
    "toled_img = torch.Tensor(toled_img.copy()).permute(2, 0, 1).unsqueeze(0)\n",
    "toled_img = toled_img.mul(2).sub(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# load pre-trained weights\n",
    "ckpt = torch.load(toled_path, map_location=torch.device(device))\n",
    "load_state_dict(model, ckpt['state_dict'])\n",
    "\n",
    "with torch.no_grad():\n",
    "    toled_out = model(toled_img.to(device))[0].cpu().permute(1,2,0).numpy()\n",
    "toled_out = (toled_out + 1)/2\n",
    "plt.figure(figsize=(10, 20))\n",
    "plt.imshow(toled_out)\n",
    "plt.title('Restored TOLED image')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}